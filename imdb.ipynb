{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract reviews for movies from IMDb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraraies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scrapy.selector import Selector\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os.path\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movies with sequals (with IMDb URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harry Potter Series\n",
    "hp0_url = 'https://www.imdb.com/title/tt0241527/reviews?ref_=tt_urv'\n",
    "hp1_url = 'https://www.imdb.com/title/tt0295297/reviews?ref_=tt_urv'\n",
    "hp2_url = 'https://www.imdb.com/title/tt0304141/reviews?ref_=tt_urv'\n",
    "hp3_url = 'https://www.imdb.com/title/tt0330373/reviews?ref_=tt_urv'\n",
    "hp4_url = 'https://www.imdb.com/title/tt0373889/reviews?ref_=tt_urv'\n",
    "hp5_url = 'https://www.imdb.com/title/tt0417741/reviews?ref_=tt_urv'\n",
    "hp6_url = 'https://www.imdb.com/title/tt0926084/reviews?ref_=tt_urv'\n",
    "hp7_url = 'https://www.imdb.com/title/tt1201607/reviews?ref_=tt_urv'\n",
    "\n",
    "# Star Wars\n",
    "sw0_url = 'https://www.imdb.com/title/tt0120915/reviews?ref_=tt_urv'\n",
    "sw1_url = 'https://www.imdb.com/title/tt0121765/reviews?ref_=tt_urv'\n",
    "sw2_url = 'https://www.imdb.com/title/tt0121766/reviews?ref_=tt_urv'\n",
    "sw3_url = 'https://www.imdb.com/title/tt0076759/reviews?ref_=tt_urv'\n",
    "sw4_url = 'https://www.imdb.com/title/tt0080684/reviews?ref_=tt_urv'\n",
    "sw5_url = 'https://www.imdb.com/title/tt0086190/reviews?ref_=tt_urv'\n",
    "sw6_url = 'https://www.imdb.com/title/tt2488496/reviews?ref_=tt_urv'\n",
    "sw7_url = 'https://www.imdb.com/title/tt2527336/reviews?ref_=tt_urv'\n",
    "sw8_url = 'https://www.imdb.com/title/tt2527338/reviews?ref_=tt_urv'\n",
    "\n",
    "# aggregate urls\n",
    "url_dict = {\n",
    "    'harry_potter': [hp0_url, hp1_url, hp2_url, hp3_url, hp4_url, hp5_url, hp6_url, hp7_url],\n",
    "    'star_wars': [sw0_url, sw1_url, sw2_url, sw3_url, sw4_url, sw5_url, sw6_url, sw7_url, sw8_url]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and save reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return reviews, titles, and rating as a dataframe \n",
    "def get_df(url):\n",
    "    # webdriver file\n",
    "    PATH = r\"C:\\chromedriver.exe\"\n",
    "    driver = webdriver.Chrome(PATH)\n",
    "    driver.get(url)\n",
    "\n",
    "    # load pages\n",
    "    sel = Selector(text = driver.page_source)\n",
    "    review_counts = sel.css('.lister .header span::text').extract_first().replace(',','').split(' ')[0]\n",
    "    more_review_pages = int(int(review_counts)/25)\n",
    "    print(f'there are {review_counts} reviews')\n",
    "    for _ in tqdm(range(more_review_pages)):\n",
    "        try:\n",
    "            css_selector = 'load-more-trigger'\n",
    "            driver.find_element(By.ID, css_selector).click()\n",
    "            time.sleep(3)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # get lists\n",
    "    rating_list = []\n",
    "    review_title_list = []\n",
    "    review_list = []\n",
    "    error_url_list = []\n",
    "    error_msg_list = []\n",
    "    reviews = driver.find_elements(By.CSS_SELECTOR, 'div.review-container')\n",
    "\n",
    "    for d in tqdm(reviews):\n",
    "        try:\n",
    "            sel2 = Selector(text = d.get_attribute('innerHTML'))\n",
    "            # review rating\n",
    "            try:\n",
    "                rating = sel2.css('.rating-other-user-rating span::text').extract_first()\n",
    "            except:\n",
    "                rating = np.NaN\n",
    "            # review text\n",
    "            try:\n",
    "                review = sel2.css('.text.show-more__control::text').extract_first()\n",
    "            except:\n",
    "                review = np.NaN\n",
    "\n",
    "            # review title\n",
    "            try:\n",
    "                review_title = sel2.css('a.title::text').extract_first()\n",
    "            except:\n",
    "                review_title = np.NaN\n",
    "\n",
    "            # append info\n",
    "            rating_list.append(rating)\n",
    "            review_title_list.append(review_title[1:-1])\n",
    "            review_list.append(review.replace('\\n', '<br /><br />'))\n",
    "\n",
    "        except Exception as e:\n",
    "            error_url_list.append(url)\n",
    "            error_msg_list.append(e)\n",
    "\n",
    "    # make the lists equal length\n",
    "    if not len(rating_list) == len(review_list) == len(review_title_list):\n",
    "        print('columns have different lengths...')\n",
    "        min_length = min(len(rating_list), len(review_list), len(review_list))\n",
    "        rating_list = rating_list[:min_length]\n",
    "        review_list = review_list[:min_length]\n",
    "        review_title_list = review_title_list[:min_length]\n",
    "\n",
    "    # convert to df\n",
    "    review_df = pd.DataFrame({\n",
    "        'Rating': rating_list,\n",
    "        'Review_Title': review_title_list,\n",
    "        'Review': review_list\n",
    "    })\n",
    "    return review_df\n",
    "\n",
    "# convert df to csv\n",
    "def save_csv(df, filepath):\n",
    "    df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the actual scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for series, urls in url_dict.items():\n",
    "    print(f'Processing {series}...')\n",
    "    index = 0\n",
    "    for url in urls:\n",
    "        filepath = f'./{series}/{index}.csv'\n",
    "        try:\n",
    "            f = open(filepath)\n",
    "            f.close()\n",
    "            print(f'{filepath} already exists')\n",
    "        except FileNotFoundError:\n",
    "            print(f'working on {filepath}...')\n",
    "            review_df = get_df(url=url)\n",
    "            save_csv(df=review_df, filepath=filepath)\n",
    "        index += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88bb0f5aeba86b8857a89854e1b72d899daa3df0ccd17c65f10c2af66593c562"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
